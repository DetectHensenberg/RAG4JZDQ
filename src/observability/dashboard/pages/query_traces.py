"""Query Traces page â€“ browse query trace history with stage waterfall."""

from __future__ import annotations

import logging
from typing import Any, Dict, List, Optional

import streamlit as st

from src.observability.dashboard.services.trace_service import TraceService

logger = logging.getLogger(__name__)


def render() -> None:
    """Render the Query Traces page."""
    st.header("ğŸ” æŸ¥è¯¢è¿½è¸ª")

    svc = TraceService()
    traces = svc.list_traces(trace_type="query")

    if not traces:
        st.info("æš‚æ— æŸ¥è¯¢è¿½è¸ªè®°å½•ã€‚è¯·å…ˆæ‰§è¡Œä¸€æ¬¡æŸ¥è¯¢ï¼")
        return

    keyword = st.text_input("æŒ‰å…³é”®è¯æœç´¢", value="", key="qt_keyword")
    if keyword.strip():
        kw = keyword.strip().lower()
        traces = [
            t for t in traces
            if kw in str(t.get("metadata", {})).lower()
            or kw in str(t.get("stages", [])).lower()
        ]

    st.subheader(f"ğŸ“‹ æŸ¥è¯¢å†å² ({len(traces)})")

    for idx, trace in enumerate(traces):
        trace_id = trace.get("trace_id", "unknown")
        started = trace.get("started_at", "â€”")
        total_ms = trace.get("elapsed_ms")
        total_label = f"{total_ms:.0f} ms" if total_ms is not None else "â€”"
        meta = trace.get("metadata", {})
        query_text = meta.get("query", "")
        source = meta.get("source", "unknown")

        query_preview = (
            query_text[:40] + "â€¦" if len(query_text) > 40 else query_text
        ) if query_text else "â€”"
        expander_title = f"ğŸ” \"{query_preview}\"  Â·  {total_label}  Â·  {started[:19]}"

        with st.expander(expander_title, expanded=(idx == 0)):
            st.markdown("#### ğŸ’¬ æŸ¥è¯¢")
            col_q, col_meta = st.columns([3, 1])
            with col_q:
                st.markdown(f"> {query_text}")
            with col_meta:
                source_emoji = "ğŸ¤–" if source == "mcp" else "ğŸ“¡"
                st.markdown(f"**æ¥æº:** {source_emoji} `{source}`")
                st.markdown(f"**Top-K:** `{meta.get('top_k', 'â€”')}`")
                st.markdown(f"**é›†åˆ:** `{meta.get('collection', 'â€”')}`")

            st.divider()

            timings = svc.get_stage_timings(trace)
            stages_by_name = {t["stage_name"]: t for t in timings}

            dense_d = (stages_by_name.get("dense_retrieval", {}).get("data") or {})
            sparse_d = (stages_by_name.get("sparse_retrieval", {}).get("data") or {})
            fusion_d = (stages_by_name.get("fusion", {}).get("data") or {})
            rerank_d = (stages_by_name.get("rerank", {}).get("data") or {})

            dense_count = dense_d.get("result_count", 0)
            sparse_count = sparse_d.get("result_count", 0)
            fusion_count = fusion_d.get("result_count", 0)
            rerank_count = rerank_d.get("output_count", 0)

            rc1, rc2, rc3, rc4, rc5 = st.columns(5)
            with rc1:
                st.metric("ç¨ å¯†å‘½ä¸­", dense_count)
            with rc2:
                st.metric("ç¨€ç–å‘½ä¸­", sparse_count)
            with rc3:
                st.metric("èåˆç»“æœ", fusion_count or (dense_count + sparse_count))
            with rc4:
                st.metric("é‡æ’å", rerank_count if rerank_d else "â€”")
            with rc5:
                st.metric("æ€»è€—æ—¶", total_label)

            _render_diagnostics(stages_by_name, dense_d, sparse_d, fusion_d, rerank_d, dense_count, sparse_count)

            st.divider()

            main_stage_names = ("query_processing", "dense_retrieval", "sparse_retrieval", "fusion", "rerank")
            main_timings = [t for t in timings if t["stage_name"] in main_stage_names]
            if main_timings:
                st.markdown("#### â±ï¸ å„é˜¶æ®µè€—æ—¶")
                chart_data = {t["stage_name"]: t["elapsed_ms"] for t in main_timings}
                st.bar_chart(chart_data, horizontal=True)
                st.table([{"é˜¶æ®µ": t["stage_name"], "è€—æ—¶ (ms)": round(t["elapsed_ms"], 2)} for t in main_timings])

            st.divider()
            st.markdown("#### ğŸ” é˜¶æ®µè¯¦æƒ…")

            tab_defs = []
            if "query_processing" in stages_by_name:
                tab_defs.append(("ğŸ”¤ æŸ¥è¯¢å¤„ç†", "query_processing"))
            if "dense_retrieval" in stages_by_name:
                tab_defs.append(("ğŸŸ¦ ç¨ å¯†æ£€ç´¢", "dense_retrieval"))
            if "sparse_retrieval" in stages_by_name:
                tab_defs.append(("ğŸŸ¨ ç¨€ç–æ£€ç´¢", "sparse_retrieval"))
            if "fusion" in stages_by_name:
                tab_defs.append(("ğŸŸ© èåˆ (RRF)", "fusion"))
            if "rerank" in stages_by_name:
                tab_defs.append(("ğŸŸª é‡æ’", "rerank"))

            if tab_defs:
                tabs = st.tabs([label for label, _ in tab_defs])
                for tab, (label, key) in zip(tabs, tab_defs):
                    with tab:
                        stage = stages_by_name[key]
                        data = stage.get("data", {})
                        elapsed = stage.get("elapsed_ms")
                        if elapsed is not None:
                            st.caption(f"â±ï¸ {elapsed:.1f} ms")
                        if key == "query_processing":
                            _render_query_processing_stage(data)
                        elif key == "dense_retrieval":
                            _render_retrieval_stage(data, "ç¨ å¯†", trace_idx=idx)
                        elif key == "sparse_retrieval":
                            _render_retrieval_stage(data, "ç¨€ç–", trace_idx=idx)
                        elif key == "fusion":
                            _render_fusion_stage(data, trace_idx=idx)
                        elif key == "rerank":
                            _render_rerank_stage(data, trace_idx=idx)
            else:
                st.info("æ— é˜¶æ®µè¯¦æƒ…ã€‚")

            _render_evaluate_button(trace, idx)


def _render_diagnostics(
    stages_by_name: Dict[str, Any],
    dense_d: Dict[str, Any],
    sparse_d: Dict[str, Any],
    fusion_d: Dict[str, Any],
    rerank_d: Dict[str, Any],
    dense_count: int,
    sparse_count: int,
) -> None:
    """Render diagnostic hints about missing or errored pipeline stages."""
    hints: list = []

    dense_err = dense_d.get("error", "")
    if dense_err:
        hints.append(("error", f"**ç¨ å¯†æ£€ç´¢å¤±è´¥:** {dense_err}"))
    elif dense_count == 0 and "dense_retrieval" in stages_by_name:
        hints.append(("warning", "ç¨ å¯†æ£€ç´¢è¿”å›äº† **0 æ¡ç»“æœ**ã€‚è¯·æ£€æŸ¥é›†åˆä¸­æ˜¯å¦å·²æœ‰ç´¢å¼•æ•°æ®ã€‚"))

    sparse_err = sparse_d.get("error", "")
    if sparse_err:
        hints.append(("error", f"**ç¨€ç–æ£€ç´¢å¤±è´¥:** {sparse_err}"))
    elif sparse_count == 0 and "sparse_retrieval" in stages_by_name:
        hints.append(("warning", "ç¨€ç– (BM25) æ£€ç´¢è¿”å›äº† **0 æ¡ç»“æœ**ã€‚BM25 ç´¢å¼•å¯èƒ½ä¸ºç©ºæˆ–å°šæœªä¸ºæ­¤é›†åˆæ„å»ºã€‚"))

    if "fusion" not in stages_by_name:
        if dense_count > 0 and sparse_count > 0:
            hints.append(("info", "å³ä½¿ä¸¤ä¸ªæ£€ç´¢å™¨éƒ½è¿”å›äº†ç»“æœï¼Œèåˆé˜¶æ®µä¹Ÿæœªè¢«è®°å½•ã€‚"))
        elif dense_count == 0 or sparse_count == 0:
            only_source = "ç¨ å¯†" if dense_count > 0 else ("ç¨€ç–" if sparse_count > 0 else "å‡æ— ")
            hints.append(("info", f"**èåˆ (RRF) å·²è·³è¿‡:** ä»… {only_source} æ£€ç´¢è¿”å›äº†ç»“æœã€‚èåˆéœ€è¦ç¨ å¯†å’Œç¨€ç–æ£€ç´¢åŒæ—¶è¿”å›ç»“æœæ‰èƒ½åˆå¹¶ã€‚"))

    if "rerank" not in stages_by_name:
        if dense_count > 0 or sparse_count > 0:
            hints.append(("info", "**é‡æ’å·²è·³è¿‡:** é‡æ’å™¨æœªå¯ç”¨æˆ–æœªé…ç½®ã€‚åœ¨ settings.yaml ä¸­å¯ç”¨ reranker ä»¥åº”ç”¨åŸºäº LLM çš„é‡æ’ã€‚"))

    if dense_count == 0 and sparse_count == 0:
        hints.append(("warning", "**æœªæ‰¾åˆ°ä»»ä½•ç»“æœã€‚** é›†åˆå¯èƒ½ä¸ºç©ºï¼Œæˆ–æŸ¥è¯¢å†…å®¹ä¸å·²ç´¢å¼•çš„å†…å®¹ä¸åŒ¹é…ã€‚è¯·å…ˆå°è¯•æ‘„å–æ•°æ®ã€‚"))

    for level, msg in hints:
        if level == "error":
            st.error(msg)
        elif level == "warning":
            st.warning(msg)
        else:
            st.info(msg)


def _render_evaluate_button(trace: Dict[str, Any], idx: int) -> None:
    """Render a Ragas evaluate button for a single query trace."""
    meta = trace.get("metadata", {})
    query = meta.get("query", "")
    if not query:
        return

    st.divider()
    col_btn, col_info = st.columns([1, 3])
    with col_btn:
        clicked = st.button(
            "ğŸ“ Ragas è¯„ä¼°",
            key=f"eval_trace_{idx}",
            help="é‡æ–°è¿è¡Œæ­¤æŸ¥è¯¢å¹¶ä½¿ç”¨ Ragas (LLM è¯„åˆ¤) æ‰“åˆ†",
        )
    with col_info:
        st.caption("ä½¿ç”¨ Ragas è¯„ä¼°å¿ å®åº¦ã€ç­”æ¡ˆç›¸å…³æ€§å’Œä¸Šä¸‹æ–‡ç²¾åº¦ã€‚å°†è°ƒç”¨ LLM â€” å¯èƒ½éœ€è¦å‡ ç§’é’Ÿã€‚")

    result_key = f"eval_result_{idx}"
    if result_key in st.session_state and not clicked:
        _display_eval_metrics(st.session_state[result_key])

    if clicked:
        with st.spinner("æ­£åœ¨è¿è¡Œ Ragas è¯„ä¼°â€¦"):
            result = _evaluate_single_trace(query, meta)
        st.session_state[result_key] = result
        _display_eval_metrics(result)


def _evaluate_single_trace(query: str, meta: Dict[str, Any]) -> Dict[str, Any]:
    """Re-run retrieval and evaluate a single query with Ragas."""
    try:
        from dataclasses import replace as dc_replace
        from src.core.settings import load_settings, EvaluationSettings
        from src.libs.evaluator.evaluator_factory import EvaluatorFactory

        settings = load_settings()
        ragas_eval = EvaluationSettings(
            enabled=True,
            provider="ragas",
            metrics=["faithfulness", "answer_relevancy", "context_precision"],
        )
        settings = dc_replace(settings, evaluation=ragas_eval)
        evaluator = EvaluatorFactory.create(settings)

        collection = meta.get("collection", "default")
        top_k = meta.get("top_k", 10)
        chunks = _retrieve_chunks(settings, query, top_k, collection)

        if not chunks:
            return {"error": "æœªæ£€ç´¢åˆ°åˆ†å— â€” æ˜¯å¦å·²ç´¢å¼•æ•°æ®ï¼Ÿ"}

        _MAX_ANSWER_CHARS = 1500
        texts = []
        for c in chunks:
            if hasattr(c, "text"):
                texts.append(c.text)
            elif isinstance(c, dict):
                texts.append(c.get("text", str(c)))
            else:
                texts.append(str(c))
        answer = " ".join(texts[:3])
        if len(answer) > _MAX_ANSWER_CHARS:
            answer = answer[:_MAX_ANSWER_CHARS]

        metrics = evaluator.evaluate(
            query=query,
            retrieved_chunks=chunks,
            generated_answer=answer,
        )
        return {"metrics": metrics}
    except ImportError as exc:
        return {"error": f"Ragas æœªå®‰è£…: {exc}"}
    except Exception as exc:
        logger.exception("Ragas evaluation failed")
        return {"error": str(exc)}


def _retrieve_chunks(settings: Any, query: str, top_k: int, collection: str) -> list:
    """Re-run HybridSearch to retrieve chunks for evaluation."""
    try:
        from src.core.query_engine.hybrid_search import create_hybrid_search
        from src.core.query_engine.query_processor import QueryProcessor
        from src.core.query_engine.dense_retriever import create_dense_retriever
        from src.core.query_engine.sparse_retriever import create_sparse_retriever
        from src.ingestion.storage.bm25_indexer import BM25Indexer
        from src.libs.embedding.embedding_factory import EmbeddingFactory
        from src.libs.vector_store.vector_store_factory import VectorStoreFactory

        vector_store = VectorStoreFactory.create(settings, collection_name=collection)
        embedding_client = EmbeddingFactory.create(settings)
        dense_retriever = create_dense_retriever(
            settings=settings, embedding_client=embedding_client, vector_store=vector_store,
        )
        from src.core.settings import resolve_path
        bm25_indexer = BM25Indexer(index_dir=str(resolve_path(f"data/db/bm25/{collection}")))
        sparse_retriever = create_sparse_retriever(
            settings=settings, bm25_indexer=bm25_indexer, vector_store=vector_store,
        )
        sparse_retriever.default_collection = collection
        query_processor = QueryProcessor()
        hybrid_search = create_hybrid_search(
            settings=settings,
            query_processor=query_processor,
            dense_retriever=dense_retriever,
            sparse_retriever=sparse_retriever,
        )
        results = hybrid_search.search(query=query, top_k=top_k)
        return results if isinstance(results, list) else results.results
    except Exception as exc:
        logger.warning("Retrieval for evaluation failed: %s", exc)
        return []


def _display_eval_metrics(result: Dict[str, Any]) -> None:
    """Display evaluation result (metrics or error)."""
    if "error" in result:
        st.error(f"âŒ è¯„ä¼°å¤±è´¥: {result['error']}")
        return

    metrics = result.get("metrics", {})
    if not metrics:
        st.warning("æœªè¿”å›æŒ‡æ ‡ã€‚")
        return

    st.markdown("**ğŸ“ Ragas è¯„åˆ†**")
    cols = st.columns(min(len(metrics), 4))
    for i, (name, value) in enumerate(sorted(metrics.items())):
        with cols[i % len(cols)]:
            st.metric(label=name.replace("_", " ").title(), value=f"{value:.4f}")


def _extract_pipeline_chunks(
    timings: List[Dict[str, Any]], meta: Dict[str, Any],
) -> Dict[str, List[Dict[str, Any]]]:
    """Extract chunk lists from each pipeline stage."""
    result: Dict[str, List[Dict[str, Any]]] = {}
    for stage in timings:
        name = stage.get("stage_name", "")
        data = stage.get("data") or {}
        chunks = data.get("chunks")
        if chunks and isinstance(chunks, list):
            result[name] = chunks
    final = meta.get("final_results") or meta.get("results")
    if final and isinstance(final, list):
        result["final"] = final
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Per-stage renderers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _render_query_processing_stage(data: Dict[str, Any]) -> None:
    """Render Query Processing stage: original query â†’ keywords."""
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**åŸå§‹æŸ¥è¯¢**")
        st.info(data.get("original_query", "â€”"))
    with c2:
        st.markdown("**æ–¹æ³•**")
        st.code(data.get("method", "â€”"))

    keywords = data.get("keywords", [])
    if keywords:
        st.markdown("**æå–çš„å…³é”®è¯**")
        st.markdown(" Â· ".join(f"`{kw}`" for kw in keywords))
    else:
        st.warning("æœªæå–åˆ°å…³é”®è¯ã€‚")


def _render_retrieval_stage(data: Dict[str, Any], label: str, *, trace_idx: int = 0) -> None:
    """Render Dense or Sparse retrieval stage."""
    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("æ–¹æ³•", data.get("method", "â€”"))
    with c2:
        extra = data.get("provider", data.get("keyword_count", "â€”"))
        extra_label = "æä¾›å•†" if "provider" in data else "å…³é”®è¯æ•°"
        st.metric(extra_label, extra)
    with c3:
        st.metric("ç»“æœæ•°", data.get("result_count", 0))

    st.markdown(f"**è¯·æ±‚ Top-K:** `{data.get('top_k', 'â€”')}`")

    chunks = data.get("chunks", [])
    if chunks:
        _render_chunk_list(chunks, prefix=f"{label.lower().replace(' ', '_')}_chunk_{trace_idx}")
    else:
        st.info(f"æœªè¿”å›{label}æ£€ç´¢ç»“æœã€‚")


def _render_fusion_stage(data: Dict[str, Any], *, trace_idx: int = 0) -> None:
    """Render Fusion (RRF) stage."""
    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("æ–¹æ³•", data.get("method", "rrf"))
    with c2:
        st.metric("è¾“å…¥åˆ—è¡¨æ•°", data.get("input_lists", "â€”"))
    with c3:
        st.metric("èåˆç»“æœæ•°", data.get("result_count", 0))

    st.markdown(f"**Top-K:** `{data.get('top_k', 'â€”')}`")

    chunks = data.get("chunks", [])
    if chunks:
        _render_chunk_list(chunks, prefix=f"fusion_chunk_{trace_idx}")
    else:
        st.info("æ— èåˆç»“æœã€‚")


def _render_rerank_stage(data: Dict[str, Any], *, trace_idx: int = 0) -> None:
    """Render Rerank stage."""
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        st.metric("æ–¹æ³•", data.get("method", "â€”"))
    with c2:
        st.metric("æä¾›å•†", data.get("provider", "â€”"))
    with c3:
        st.metric("è¾“å…¥æ•°", data.get("input_count", "â€”"))
    with c4:
        st.metric("è¾“å‡ºæ•°", data.get("output_count", "â€”"))

    chunks = data.get("chunks", [])
    if chunks:
        _render_chunk_list(chunks, prefix=f"rerank_chunk_{trace_idx}")
    else:
        st.info("æ— é‡æ’ç»“æœã€‚")


def _render_chunk_list(chunks: List[Dict[str, Any]], prefix: str = "chunk") -> None:
    """Render a list of chunk dicts as a compact, readable table with expandable text."""
    for ci, chunk in enumerate(chunks):
        score = chunk.get("score", 0)
        text = chunk.get("text", "")
        chunk_id = chunk.get("chunk_id", "")
        source = chunk.get("source", "")
        title = chunk.get("title", "")

        if score >= 0.8:
            score_bar = "ğŸŸ¢"
        elif score >= 0.5:
            score_bar = "ğŸŸ¡"
        else:
            score_bar = "ğŸ”´"

        header = f"{score_bar} **#{ci + 1}** â€” åˆ†æ•°: `{score:.4f}`"
        if title:
            header += f" â€” {title}"

        with st.expander(header, expanded=False):
            cols = st.columns([2, 3])
            with cols[0]:
                st.caption(f"åˆ†å— ID: `{chunk_id}`")
            with cols[1]:
                if source:
                    st.caption(f"æ¥æº: `{source}`")
            if text:
                st.text_area(
                    f"{prefix}_{ci}",
                    value=text,
                    height=max(80, min(len(text) // 2, 400)),
                    disabled=True,
                    label_visibility="collapsed",
                )
            else:
                st.caption("_æ— æ–‡æœ¬å†…å®¹_")


def _find_stage(timings, name):
    """Find a stage dict by name, or None."""
    for t in timings:
        if t["stage_name"] == name:
            return t
    return None
